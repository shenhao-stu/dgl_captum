{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ef35ea4",
   "metadata": {},
   "source": [
    "# Getting started with Captum "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5526b869",
   "metadata": {},
   "source": [
    "In this tutorial we demonstrate how to apply feature attribution methods to graphs. Specifically, we try to find the most important nodes and edges for each instance prediction.\n",
    "\n",
    "We use cora dataset from dgl.data. The Cora dataset used in this tutorial only consists of one single graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d3d99b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and import required packages.\n",
    "import dgl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl.data\n",
    "from dgl.nn import GraphConv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8981045d",
   "metadata": {},
   "source": [
    "## Loading Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "443d280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "# A DGL Dataset object may contain one or multiple graphs.\n",
    "# The Cora dataset used in this tutorial only consists of one single graph.\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e62909a",
   "metadata": {},
   "source": [
    "## Define the model\n",
    "This tutorial will build a two-layer Graph Convolutional Network (GCN). Each layer computes new node representations by aggregating neighbor information. What's more, we use GraphConv which supports edge_weight as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d099f828",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, in_feat, g, edge_weight=None):\n",
    "        h = self.conv1(g, in_feat, edge_weight=edge_weight)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h, edge_weight=edge_weight)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d48c40",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "Training this GCN is similar to training other PyTorch neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77a3c0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yingpei/opt/anaconda3/envs/dgl/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes).to(device)\n",
    "g = g.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "features = g.ndata['feat']\n",
    "labels = g.ndata['label']\n",
    "train_mask = g.ndata['train_mask']\n",
    "\n",
    "for epoch in range(1,201):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # Forward\n",
    "    logits = model(features, g)\n",
    "    \n",
    "    # Compute prediction\n",
    "    pred = logits.argmax(1)\n",
    "    \n",
    "    # Compute loss\n",
    "    # Note that you should only compute the losses of the nodes in the training set.\n",
    "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "    \n",
    "    # Backward\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321c5244",
   "metadata": {},
   "source": [
    "## Explaining the predictions\n",
    "We use the [captum](https://captum.ai/) library for calculating the attribution values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e7e10b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Select the node with index 10 for interpretability analysis\n",
    "output_idx = 10\n",
    "target = int(g.ndata['label'][output_idx])\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af226c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yingpei/opt/anaconda3/envs/dgl/lib/python3.9/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2708, 1433])\n"
     ]
    }
   ],
   "source": [
    "# import captum\n",
    "from captum.attr import IntegratedGradients\n",
    "from functools import partial\n",
    "\n",
    "# Node explainability\n",
    "ig = IntegratedGradients(partial(model.forward, g=g))\n",
    "ig_attr_node = ig.attribute(g.ndata['feat'], target=target,\n",
    "                            internal_batch_size=g.num_nodes(), n_steps=50)\n",
    "print(ig_attr_node.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bcd8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale attributions to [0, 1]:\n",
    "ig_attr_node = ig_attr_node.abs().sum(dim=1)\n",
    "ig_attr_node /= ig_attr_node.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43d47145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13340db6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1533, 0.2043, 0.3890,  ..., 0.2280, 0.1629, 0.1877],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_attr_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab445c18",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yingpei/opt/anaconda3/envs/dgl/lib/python3.9/site-packages/captum/attr/_utils/batching.py:45: UserWarning: Internal batch size cannot be less than the number of input examples. Defaulting to internal batch size of 10556 equal to the number of examples.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10556])\n"
     ]
    }
   ],
   "source": [
    "def model_forward(edge_mask, g):\n",
    "    out = model(g.ndata['feat'],g,edge_weight=edge_mask)\n",
    "    return out\n",
    "\n",
    "# Edge explainability\n",
    "edge_mask = torch.ones(g.num_edges()).requires_grad_(True).to(device)\n",
    "ig = IntegratedGradients(partial(model_forward, g=g))\n",
    "ig_attr_edge = ig.attribute(edge_mask, target=target,\n",
    "                            internal_batch_size=g.num_nodes(), n_steps=50)\n",
    "print(ig_attr_edge.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "955f1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale attributions to [0, 1]:\n",
    "g_attr_edge = ig_attr_edge.abs()\n",
    "ig_attr_edge /= ig_attr_edge.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "298d61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a8dc83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.2232, -0.2149, -0.2420,  ..., -0.0056, -0.0506, -0.0463],\n",
       "       dtype=torch.float64, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ig_attr_edge"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dgl] *",
   "language": "python",
   "name": "conda-env-dgl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
